# Stubs for bayesian_hmm.hdphmm (Python 3)
#
# NOTE: This dynamically typed stub was automatically generated by stubgen.

import numpy
import typing
from . import bayesian_model
from .bayesian_model import hyperparameter
from .chain import Chain, resample_latent_sequence
from typing import Any

class HDPHMM:
    chains: Any = ...
    sticky: Any = ...
    alpha: Any = ...
    gamma: Any = ...
    kappa: Any = ...
    beta_emission: Any = ...
    transition_model: Any
    emission_model: Any
    emission_counts: Any = ...
    transition_counts: Any = ...
    emissions: Any = ...
    states: Any = ...
    def __init__(self, emission_sequences: typing.Iterable[typing.Sequence[bayesian_model.State]], emissions: typing.Optional[typing.Set[bayesian_model.State]]=..., sticky: bool=..., alpha: hyperparameter.Hyperparameter=..., gamma: hyperparameter.Hyperparameter=..., kappa: bayesian_model.Hyperparameter=..., beta_emission: bayesian_model.Hyperparameter=...) -> None: ...
    @property
    def initialised(self) -> bool: ...
    @initialised.setter
    def initialised(self, value: typing.Any) -> None: ...
    @property
    def c(self) -> int: ...
    @property
    def k(self) -> int: ...
    @property
    def n(self) -> int: ...
    def to_array(self) -> numpy.array: ...
    def state_generator(self) -> typing.Generator[bayesian_model.State, None, None]: ...
    def initialise(self, k: int=...) -> None: ...
    def update_states(self) -> None: ...
    def update_counts(self) -> None: ...
    def print_probabilities(self, digits: int=...) -> typing.Tuple[str, str]: ...
    def chain_log_likelihoods(self) -> typing.List[float]: ...
    def log_likelihood(self) -> float: ...
    def resample_chains(self, ncores: int = ...) -> None: ...
    def maximise_hyperparameters(self) -> None: ...
    def mcmc(self, n: int=..., burn_in: int=..., save_every: int=..., ncores: int=..., verbose: Any=...) -> typing.Dict[str, typing.List[typing.Any]]: ...
